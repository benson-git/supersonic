server:
  port: 9080
  compression:
    enabled: true
    min-response-size: 1024
    mime-types: application/javascript,application/json,application/xml,text/html,text/xml,text/plain,text/css,image/*

spring:
  h2:
    console:
      path: /h2-console/semantic
      enabled: true
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://mysql8-test01-mysql-master-3489.ot1.gz.paas.cvtecs.com:3489/chatdata
    username: chatdata
    password: Ae?15LjU
  autoconfigure:
    exclude:
      - spring.dev.langchain4j.spring.LangChain4jAutoConfig
      - spring.dev.langchain4j.openai.spring.AutoConfig
      - spring.dev.langchain4j.ollama.spring.AutoConfig
      - spring.dev.langchain4j.azure.openai.spring.AutoConfig
      - spring.dev.langchain4j.azure.aisearch.spring.AutoConfig
      - spring.dev.langchain4j.anthropic.spring.AutoConfig
mybatis:
  mapper-locations=classpath:mappers/custom/*.xml,classpath*:/mappers/*.xml

authentication:
  enable: true
  exclude:
    path: /api/auth/user/register,/api/auth/user/login
  token:
    http:
      header:
        key: Authorization

logging:
  level:
    dev.langchain4j: DEBUG
    dev.ai4j.openai4j: DEBUG

s2:
  pyllm:
    url: http://127.0.0.1:9092

  parser:
    url: ${s2.pyllm.url}
    strategy: ONE_PASS_SELF_CONSISTENCY
    exemplar-recall:
      number: 10
    few-shot:
      number: 5
    self-consistency:
      number: 1
    multi-turn:
      enable: false

  corrector:
    additional:
      information: true
    date: true
  functionCall:
    url: ${s2.pyllm.url}

  embedding:
    url: ${s2.pyllm.url}
    persistent:
      path: /tmp

  demo:
    names: S2VisitsDemo,S2ArtistDemo
    enableLLM: true

# swagger配置
swagger:
  title: 'SuperSonic平台接口文档'
  base:
    package: com.tencent.supersonic
  description: 'SuperSonic平台接口文档'
  url: ''
  contact:
    name:
    email:
    url: ''
  version: 3.0


langchain4j:
  open-ai:
    chat-model:
      # Replace with your LLM configs
      # Note: The default API key `demo` is provided by langchain4j community
      #       which limits 1000 tokens per request.
      base-url: ${OPENAI_API_BASE:https://aihubmix.com/v1}
      api-key: ${OPENAI_API_KEY:sk-lZ9dlL3R9rgG5zYg62057024228f4d8b851eEeC407F219D8}
      model-name: ${OPENAI_MODEL_NAME:gpt-3.5-turbo}
      temperature: ${OPENAI_TEMPERATURE:0.0}
      timeout: ${OPENAI_TIMEOUT:PT60S}
#    embedding-model:
#      base-url: ${OPENAI_API_BASE:https://aihubmix.com/v1}
#      api-key: ${OPENAI_API_KEY:sk-lZ9dlL3R9rgG5zYg62057024228f4d8b851eEeC407F219D8}
#      model-name: ${OPENAI_MODEL_NAME:gpt-3.5-turbo}
#  dashscope:
#    chat-model:
#      api-key: ${OPENAI_API_KEY:demo}
#      model-name: qwen-max-1201
#    embedding-model:
#      api-key: ${OPENAI_API_KEY:demo}
  in-memory:
#    embedding-model:
#      model-name: bge-small-zh
      #modelPath: /data/model.onnx
      #vocabularyPath: /data/onnx_vocab.txt
    embedding-store:
      file-path: /tmp

  zhipu:
#    chat-model:
#      base-url: ${ZHIPU_API_BASE:https://open.bigmodel.cn/api/paas/v4/}
#      api-key: ${ZHIPU_API_KEY:9f822561220238c490050e6e60896e95.XCG5eL4X8ni1CjnB}
#      model-name: ${ZHIPU_MODEL_NAME:glm-4}
#      temperature: ${ZHIPU_TEMPERATURE:0.0}
#      timeout: ${ZHIPU_TIMEOUT:PT60S}
    embedding-model:
      base-url: ${ZHIPU_API_BASE:https://open.bigmodel.cn/}
      api-key: ${ZHIPU_API_KEY:9f822561220238c490050e6e60896e95.XCG5eL4X8ni1CjnB}
      model: ${ZHIPU_MODEL_NAME:embedding-2}


#cas单点登录
cas:
  # prefixUrl: https://op.cvte.com/d72f1f3c12904d359e1de7e99cac61e8
  prefixUrl: https://op-fat.cvte.com/b9114441c4544c5093ce5754a9f8b6c4

dify:
  url: https://dify.cvte.com/v1/chat-messages
  key: Bearer app-iPTMT6gRbDvx5K9tlAa8cfrE
