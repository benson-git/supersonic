server:
  port: 9080
  compression:
    enabled: true
    min-response-size: 1024
    mime-types: application/javascript,application/json,application/xml,text/html,text/xml,text/plain,text/css,image/*

spring:
  h2:
    console:
      path: /h2-console/semantic
      enabled: true
  datasource:
    driver-class-name: org.h2.Driver
    schema: classpath:db/schema-h2.sql
    data: classpath:db/data-h2.sql
    url: jdbc:h2:mem:semantic;DATABASE_TO_UPPER=false
    username: root
    password: semantic
#    driver-class-name: com.mysql.cj.jdbc.Driver
#    #schema: classpath:db/scddhema-h2.sql
#    #data: classpath:db/data-h2.sql
#    url: jdbc:mysql://10.21.46.128:3306/datavines?useUnicode=true&characterEncoding=UTF-8&useSSL=false
#    username: databin
#    password: AxfOk4rY0SpHz

mybatis:
  mapper-locations=classpath:mappers/custom/*.xml,classpath*:/mappers/*.xml

authentication:
  enable: true
  exclude:
    path: /api/auth/user/register,/api/auth/user/login
  token:
    http:
      header:
        key: Authorization

logging:
  level:
    dev.langchain4j: DEBUG
    dev.ai4j.openai4j: DEBUG

s2:
  pyllm:
    url: http://127.0.0.1:9092

  parser:
    url: ${s2.pyllm.url}
    strategy: ONE_PASS_SELF_CONSISTENCY
    exemplar-recall:
      number: 10
    few-shot:
      number: 5
    self-consistency:
      number: 5
    multi-turn:
      enable: true

  corrector:
    additional:
      information: true
    date: true
  functionCall:
    url: ${s2.pyllm.url}

  embedding:
    url: ${s2.pyllm.url}
    persistent:
      path: /tmp

  demo:
    names: S2VisitsDemo,S2ArtistDemo
    enableLLM: true

  langchain4j:
    #1.chat-model
    chat-model:
      provider: open_ai
      openai:
        # Replace with your LLM configs
        # Note: The default API key `demo` is provided by langchain4j community
        #       which limits 1000 tokens per request.
        base-url: https://aihubmix.com/v1
        api-key: sk-PQXoJIdEZhdnWClvC38559546c1945EcAa1e11570eE99b6d
        model-name: gpt-4o
        temperature: 0.0
        timeout: PT60S
    #2.embedding-model
    #2.1 in_memory(default)
    embedding-model:
      provider: in_process
    #      inProcess:
    #        modelPath: /data/model.onnx
    #        vocabularyPath: /data/onnx_vocab.txt
    #        shibing624/text2vec-base-chinese
    #2.2 open_ai
    #  embedding-model:
    #    provider: open_ai
    #    openai:
    #      api-key: api_key
    #      modelName: all-minilm-l6-v2.onnx

    #2.2 hugging_face
    #  embedding-model:
    #    provider: hugging_face
    #    hugging-face:
    #      access-token: hg_access_token
    #      model-id: sentence-transformers/all-MiniLM-L6-v2
    #      timeout: 1h

# swagger配置
swagger:
  title: 'SuperSonic平台接口文档'
  base:
    package: com.tencent.supersonic
  description: 'SuperSonic平台接口文档'
  url: ''
  contact:
    name:
    email:
    url: ''
  version: 3.0
